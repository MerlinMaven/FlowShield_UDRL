=============
Bibliography
=============

Key references for understanding FlowShield-UDRL.

Core Methods
------------

Upside-Down Reinforcement Learning
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. [Schmidhuber2019] Schmidhuber, J. (2019). 
   Reinforcement learning upside down: Don't predict rewards -- just map them to actions. 
   *arXiv preprint arXiv:1912.02875*.

.. [Srivastava2019] Srivastava, R. K., Shyam, P., Muber, F., Ollivier, Y., & Schmidhuber, J. (2019).
   Training agents using upside-down reinforcement learning.
   *arXiv preprint arXiv:1912.02877*.

Flow Matching
^^^^^^^^^^^^^

.. [Lipman2022] Lipman, Y., Chen, R. T., Ben-Hamu, H., Nickel, M., & Le, M. (2022).
   Flow matching for generative modeling.
   *arXiv preprint arXiv:2210.02747*.

.. [Tong2023] Tong, A., Malkin, N., Huguet, G., Zhang, Y., Rector-Brooks, J., 
   Fatras, K., Wolf, G., & Bengio, Y. (2023).
   Conditional flow matching: Simulation-free dynamic optimal transport.
   *arXiv preprint arXiv:2302.00482*.

.. [Liu2022] Liu, X., Gong, C., & Liu, Q. (2022).
   Flow straight and fast: Learning to generate and transfer data with rectified flow.
   *arXiv preprint arXiv:2209.03003*.

Diffusion Models
^^^^^^^^^^^^^^^^

.. [Ho2020] Ho, J., Jain, A., & Abbeel, P. (2020).
   Denoising diffusion probabilistic models.
   *Advances in Neural Information Processing Systems*, 33, 6840-6851.

.. [Song2020] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020).
   Score-based generative modeling through stochastic differential equations.
   *arXiv preprint arXiv:2011.13456*.

.. [Song2021] Song, J., Meng, C., & Ermon, S. (2021).
   Denoising diffusion implicit models.
   *arXiv preprint arXiv:2010.02502*.

Continuous Normalizing Flows
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. [Chen2018] Chen, R. T., Rubanova, Y., Bettencourt, J., & Duvenaud, D. K. (2018).
   Neural ordinary differential equations.
   *Advances in Neural Information Processing Systems*, 31.

.. [Grathwohl2018] Grathwohl, W., Chen, R. T., Bettencourt, J., Sutskever, I., & Duvenaud, D. (2018).
   FFJORD: Free-form continuous dynamics for scalable reversible generative models.
   *arXiv preprint arXiv:1810.01367*.

Quantile Regression
^^^^^^^^^^^^^^^^^^^

.. [Koenker2001] Koenker, R., & Hallock, K. F. (2001).
   Quantile regression.
   *Journal of Economic Perspectives*, 15(4), 143-156.

.. [Dabney2018] Dabney, W., Rowland, M., Bellemare, M. G., & Munos, R. (2018).
   Distributional reinforcement learning with quantile regression.
   *AAAI Conference on Artificial Intelligence*.

Safe Reinforcement Learning
---------------------------

.. [Amodei2016] Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., & Mané, D. (2016).
   Concrete problems in AI safety.
   *arXiv preprint arXiv:1606.06565*.

.. [Garcia2015] García, J., & Fernández, F. (2015).
   A comprehensive survey on safe reinforcement learning.
   *Journal of Machine Learning Research*, 16(1), 1437-1480.

.. [Berkenkamp2017] Berkenkamp, F., Turchetta, M., Schoellig, A., & Krause, A. (2017).
   Safe model-based reinforcement learning with stability guarantees.
   *Advances in Neural Information Processing Systems*, 30.

Goal-Conditioned RL
-------------------

.. [Kaelbling1993] Kaelbling, L. P. (1993).
   Learning to achieve goals.
   *IJCAI*, 93, 1094-1098.

.. [Schaul2015] Schaul, T., Horgan, D., Gregor, K., & Silver, D. (2015).
   Universal value function approximators.
   *International Conference on Machine Learning*, 1312-1320.

.. [Andrychowicz2017] Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., 
   Welinder, P., McGrew, B., Tobin, J., Abbeel, P., & Zaremba, W. (2017).
   Hindsight experience replay.
   *Advances in Neural Information Processing Systems*, 30.

Out-of-Distribution Detection
-----------------------------

.. [Hendrycks2017] Hendrycks, D., & Gimpel, K. (2017).
   A baseline for detecting misclassified and out-of-distribution examples in neural networks.
   *ICLR*.

.. [Nalisnick2019] Nalisnick, E., Matsukawa, A., Teh, Y. W., Gorur, D., & Lakshminarayanan, B. (2019).
   Do deep generative models know what they don't know?
   *ICLR*.

.. [Ren2019] Ren, J., Liu, P. J., Fertig, E., Snoek, J., Poplin, R., Depristo, M. A., 
   Dillon, J. V., & Lakshminarayanan, B. (2019).
   Likelihood ratios for out-of-distribution detection.
   *Advances in Neural Information Processing Systems*, 32.

Environments
------------

.. [Brockman2016] Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., 
   Tang, J., & Zaremba, W. (2016).
   OpenAI Gym.
   *arXiv preprint arXiv:1606.01540*.

.. [Leurent2018] Leurent, E. (2018).
   An environment for autonomous driving decision-making.
   *GitHub repository: highway-env*.

Neural Network Architectures
----------------------------

.. [Vaswani2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., 
   Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).
   Attention is all you need.
   *Advances in Neural Information Processing Systems*, 30.

.. [Rahimi2007] Rahimi, A., & Recht, B. (2007).
   Random features for large-scale kernel machines.
   *Advances in Neural Information Processing Systems*, 20.

Optimization
------------

.. [Kingma2014] Kingma, D. P., & Ba, J. (2014).
   Adam: A method for stochastic optimization.
   *arXiv preprint arXiv:1412.6980*.

.. [Loshchilov2017] Loshchilov, I., & Hutter, F. (2017).
   SGDR: Stochastic gradient descent with warm restarts.
   *ICLR*.
